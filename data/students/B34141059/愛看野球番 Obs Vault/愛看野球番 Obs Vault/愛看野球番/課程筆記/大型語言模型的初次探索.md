---
時間: 2026-01-21
標題: 大型語言模型的初次探索
授課教師: 李韶曼
tags:
  - LLM
  - 大型語言模型
  - AI
aliases:
  - LLM
---
李韶曼
法律人
法律結合ai、大型語言模型llm


初步理解
如何訓練
檢索增強


# 初步理解AI

LLM五大應用場景：
- 文案生成
- 語言翻譯
- 對話機器人
- 問答系統
- 生成程式碼

## LLM大型語言模型
輸入問題——>黑盒子——>答案

VLM視覺語言模型
輸入圖片——>黑盒子——>描述

餵給模型大量語言
根據文字上下文，預測文字的機率分布或生成新文字
餵的模型不同（時間空間），生成出來的東西也會不一樣

每個字都是代號
中文，如果拆成個別的字，會造成理解困難/斷詞問題
拆成語意單元來理解

訓練的資料很繁亂
天天拉霸中大獎 VS 今天天氣如何
「天天」應該如何切割？

各大語言模型都有屬於自己的公式/通則
- 英文都傾向切一兩個字母來理解
- 中文傾向切一兩個字來理解
	摒棄過往語言學家的文法變化，都交給電腦去算機率

## 電腦怎麼接龍？（學習「語用」）
倒裝句 eg.
反諷 eg.哇你真厲害呀考試沒來考

兩個蘋果 怎麼分開理解
- 蘋果——>手機——>iphone——>新版
- 蘋果——>樹——>牛頓——>青森
	- 放入LLM的一塊，變成可以被訓練的詞向量
	- 成為模型的一層，自動從下游任務中學習到的適當的語言向量表示
	- 根據任務、上下文動態學習

有語病、不適當的語句
eg.
1. 小美把禮物送給小芳，她很開心。
	「她」是誰？
2. 你真厲害，連這麼簡單的事都能搞砸。
	 厲害、搞砸——>反諷？
3. 小明拿出手機塞進杯子裡。
	變魔術、上一代的手機？
語句需要上下文理解
解法：塞給模型更多文本

## AI的錯亂
第一代的語料，語言學家搜集，精挑細選，
文本不夠多，成本高，沒辦法解決語用不夠成熟的問題
2010年 社群媒體興起，社群資料量指數攀升
	bbs、部落格、dcard、ig、fb

一個一個字的輸入——>反應上下文的關係——>記憶功能
	資料太多
LSTM可決定要不要記得或遺忘

現代的LLM
- 可捕捉更長文字間的關係
- 少記憶瓶頸，每個字都可以和整段文字做關聯，不需要只靠少數向量記憶
運算資源、運算量的突破

但還是有限制，如果丟太多資料，ai還是會錯亂

# 如何訓練

基本訓練流程 - Roadmap
1. 準備訓練資料。
2. 選擇要 Train 的模型。
3. 想好要怎麼 Train。
4. 想好要怎麼算分數。
5. 想好要怎麼更新模型。

## 準備訓練資料

有的比較大眾的資料，可以從網路大量資料中學會
如果是小眾的，可能就要把自己的想法教會模型

1. Data Preparation
	- 資料清洗
		我們不希望模型學會的事情
		大量重複的資料
	- 特徵工程
		根據模型用途不一樣，特別要讓模型學會什麼
	- 資料標記
		幫模型標正確答案。
		標記（Labeling）讓模型有「正確答案」可以學習。
		大多會採用結構化資料格式，有助於重用與模組化設計。
		
		（模型類型/答案可能的樣式）
			數值預測模型 ：數值向量 （e.g.［0.5，-1.2,3.3］）
			圖片模型         ：文字、一整張圖片
			Transformer   ：文字 
1. Model Design
	- 學習率
	- batch size
	- 模型如何串接
2. Training
	- Loss function設計
	- Optimizer 設計
- 訓練流程設計
4. Validation
	- Validation set
	- Human feedback
	利用在地使用者feedback，調教模型
	這次模型中，使用者生氣、重新生成、罵他，成為下一次模型的參考資料


大型語言模型的訓練很難
美國中國、少數歐洲國家在做而已

### 基本訓練流程 Finetune

小團隊 免強可以做的事情
目標
- 想針對特定下游任務
- 想延伸現有模型能力
- 想快速應用大模型能力到新任務
常見手法：
- Full Finetune
	針對特定任務大幅提升準確度。
	資料量大、可承受較高訓練成本。
- LORA
	記憶體受限的設備上進行微調。
	多任務共享同一基礎模型，只替換LORA 模組。
- 蒸餾
	將大型模型壓縮成小模型，部署於邊緣裝置。
	保留準確率的同時降低推理延遲。

雖然小，但不同用法，還是可以訓練到一定效果的

BaseModel要用什麼？
![[截圖 2026-01-21 上午10.49.25.png|500]]

eg. OpenAI platform
![[截圖 2026-01-21 上午10.55.15.png|500]]
這段文字被切成88個token，但有些字像「韶」被拆成兩個token來理解

- 使用AI介面是用對話的方式
	下對話指令之後，會跑程式碼讓模型畫畫或說話
- 如果與模型直接互動，比如google ai studio，要下「System Prompt 」
	可以直接跟ai自己跑出來的程式碼對話
可以框架ai的輸出，不是毫無邊界的輸出
eg. 輸入自殺訊息，應該要輸出專線、心理醫師資訊，不是鼓勵


# 檢索增強
如何利用prompt設定框架加強LLM的檢索
RAG

我的huffingface_token
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